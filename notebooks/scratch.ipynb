{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.path.dirname(__vsc_ipynb_file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_smi\n",
    "jax_smi.initialise_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext line_profiler\n",
    "from scripts.train_phi_sae import main\n",
    "import saex.trainer_cache\n",
    "import saex.models.micrlhf_model\n",
    "# %lprun -f saex.trainer_cache.BufferTrainer.train main(layer=11, is_gated=True, sparsity_coefficient=1.4e-5, n_devices=4)\n",
    "# %lprun -f saex.models.micrlhf_model.MicrlhfModel.__call__ main(layer=11, is_gated=True, sparsity_coefficient=1.4e-5, n_devices=4)\n",
    "# %lprun -f saex.models.micrlhf_model.MicrlhfModel.encode_texts main(layer=11, is_gated=True, sparsity_coefficient=1.4e-5, n_devices=4)\n",
    "main(layer=11, is_gated=True, sparsity_coefficient=4e-6, n_devices=4, use_recip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_gpt2_sae import main\n",
    "main(size=2, layer=16, push_to_hub=(\"nev/gpt2_medium_saes-saex-test\", \"l16-test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saex.iterable_dataset import IterableDatasetConfig\n",
    "from saex.models.micrlhf_model import MicrlhfModelConfig\n",
    "from saex.model_haver import ModelHaver\n",
    "from saex.sae import SAEConfig\n",
    "from more_itertools import chunked\n",
    "\n",
    "\n",
    "n_features = 3072\n",
    "batch_size = 64\n",
    "sae_config = SAEConfig(\n",
    "    n_dimensions=n_features,\n",
    "    sparsity_loss_type=\"l1\",\n",
    "    sparsity_coefficient=0,\n",
    "    batch_size=batch_size,\n",
    "    expansion_factor=32,\n",
    "    use_encoder_bias=True,\n",
    "    remove_decoder_bias=False,\n",
    "    encoder_init_method=\"orthogonal\",\n",
    "    decoder_init_method=\"pseudoinverse\",\n",
    "    decoder_bias_init_method=\"zeros\",\n",
    "    reconstruction_loss_type=\"mse_batchnorm\",\n",
    "    project_updates_from_dec=True,\n",
    "    death_loss_type=\"dm_ghost_grads\",\n",
    "    death_penalty_threshold=5e-7,\n",
    "    death_penalty_coefficient=0.25,\n",
    "    dead_after=1_000,\n",
    "    buffer_size=2_000,\n",
    "    restrict_dec_norm=\"exact\",\n",
    "    sparsity_tracking_epsilon=0.1,\n",
    "    is_gated=True,\n",
    ")\n",
    "dataset_config = IterableDatasetConfig(\n",
    "    dataset_name=\"nev/openhermes-2.5-phi-format-text\",\n",
    ")\n",
    "model_config = MicrlhfModelConfig(\n",
    "    tokenizer_path=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    gguf_path=\"weights/phi-3-16.gguf\",\n",
    "    device_map=\"tpu:0\",\n",
    "    use_flash=False,\n",
    "    layer=11,\n",
    "    max_seq_len=64,\n",
    ")\n",
    "haver = ModelHaver(model_config=model_config, sae_config=sae_config,\n",
    "                    dataset_config=dataset_config,\n",
    "                    sae_restore=\"weights/phi-l11-gated.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haver.sae.push_to_hub(\"nev/phi-3-4k-saex-test\", \"l11-test1-recip-l0-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "\n",
    "tokens_processed = 0\n",
    "activ_cache = defaultdict(list)\n",
    "for texts in chunked(bar := tqdm(haver.create_dataset()), batch_size):\n",
    "    activations, model_misc = haver.model(texts)\n",
    "    mask = model_misc.get(\"mask\")\n",
    "    pre_relu, hiddens = haver.sae.encode(activations)\n",
    "    bar.set_postfix(l0=((hiddens != 0).sum(-1) * mask).mean() / mask.mean())\n",
    "    indices = jnp.arange(len(mask)) + tokens_processed\n",
    "    for feat in (hiddens != 0).any(axis=0).nonzero()[0]:\n",
    "        greats = hiddens[:, feat]\n",
    "        activ_cache[int(feat)].extend(zip(indices[mask], greats[mask]))\n",
    "    # hiddens = np.asarray(hiddens.astype(jnp.float16))\n",
    "    # for i, h in enumerate(hiddens):\n",
    "    #     if not mask[i]:\n",
    "    #         continue\n",
    "    #     active_features = np.nonzero(h)[0]\n",
    "    #     feature_activations = h[active_features]\n",
    "    #     for f, a in zip(active_features, feature_activations):\n",
    "    #         activ_cache[int(f)].append((tokens_processed + i, float(a)))\n",
    "    tokens_processed += hiddens.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(feature, thresh=6.0):\n",
    "    cache = activ_cache[feature]\n",
    "    if not cache:    \n",
    "        return\n",
    "    tokens, activs = zip(*cache)\n",
    "    if max(activs) < thresh:\n",
    "        return\n",
    "    freq = len(tokens) / tokens_processed\n",
    "    print(freq)\n",
    "    if freq > 0.03:\n",
    "        return\n",
    "    tokens_viewed = 0\n",
    "    sli = 24\n",
    "    for texts in chunked(tqdm(haver.create_dataset()), batch_size):\n",
    "        toks = haver.model.to_tokens(texts)\n",
    "        all_tokens = [t for tok in toks for t in tok]\n",
    "        proc = sum(map(len, toks))\n",
    "        all_token_ids = [tokens_viewed + i for i in range(proc)]\n",
    "        for i, t in enumerate(all_token_ids):\n",
    "            if t in tokens:\n",
    "                activ = activs[tokens.index(t)]\n",
    "                if activ < thresh:\n",
    "                    continue\n",
    "                print(activ, repr(haver.model.decode(all_tokens[max(0, i - sli + 1):i+1])),\n",
    "                      repr(haver.model.decode(all_tokens[i+1:i+5])))\n",
    "        tokens_viewed += proc\n",
    "        if tokens_viewed > max(tokens):\n",
    "            break\n",
    "for i in range(10_000, 10_0100):\n",
    "    visualize(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_gated_sae import main\n",
    "main(cache_batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_phi_sae import main\n",
    "main(layer=11, is_gated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_phi_sae import main\n",
    "main(layer=11, is_gated=True, sparsity_coefficient=4.2e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_phi_sae import main\n",
    "main(layer=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_gated_sae import main\n",
    "main(is_xl=True, layer=20, cache_batch_size=256)\n",
    "# main(is_xl=True, layer=30, cache_batch_size=256, restore=\"weights/gpt2-20-gated.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_gpt2_sae import main\n",
    "main(restore=\"weights/gpt2-20-base.safetensors\", layer=32)\n",
    "# python -m scripts.train_gpt2_sae --save_steps 0 --is_xl=False --layer=9\n",
    "# main(save_steps=0, is_xl=False, layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saex-U2at97x7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
