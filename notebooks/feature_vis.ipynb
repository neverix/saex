{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.cache/pypoetry/virtualenvs/saex-U2at97x7-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from saex.iterable_dataset import IterableDatasetConfig\n",
    "from saex.models.micrlhf_model import MicrlhfModelConfig\n",
    "from saex.haver import ModelHaver, SAEHaver\n",
    "from saex.sae import SAEConfig\n",
    "from more_itertools import chunked\n",
    "\n",
    "\n",
    "n_features = 3072\n",
    "batch_size = 64\n",
    "layer = 12\n",
    "dataset_config = IterableDatasetConfig(\n",
    "    dataset_name=\"nev/openhermes-2.5-phi-format-text\",\n",
    "    # dataset_name=\"nev/generated-phi-format-text\",\n",
    ")\n",
    "model_config = MicrlhfModelConfig(\n",
    "    tokenizer_path=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    gguf_path=\"../weights/phi-3-16.gguf\",\n",
    "    device_map=\"auto\",\n",
    "    use_flash=False,\n",
    "    layer=layer,\n",
    "    max_seq_len=128,\n",
    ")\n",
    "sae_config = SAEConfig(\n",
    "    n_dimensions=n_features,\n",
    "    batch_size=batch_size,\n",
    "    expansion_factor=32,\n",
    "    use_encoder_bias=True,\n",
    "    remove_decoder_bias=False,\n",
    "    encoder_init_method=\"orthogonal\",\n",
    "    decoder_init_method=\"pseudoinverse\",\n",
    "    decoder_bias_init_method=\"zeros\",\n",
    "    is_gated=False,\n",
    ")\n",
    "haver = ModelHaver(model_config=model_config, dataset_config=dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.pyenv/versions/3.12.3/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-20 03:17:31--  https://huggingface.co/nev/phi-3-4k-saex-test/resolve/main/l12-test-run-5-7.00E-06/sae_weights.safetensors?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 108.156.211.95, 108.156.211.125, 108.156.211.51, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.156.211.95|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/eb/d8/ebd889d6ac58573e8e8a7aa1176d4d357581a6da60135b94aca378fddf4e9e54/a8414dcfc8cc29b6b9c7b3e02f39b6d319fcf89f9a08a687ae488a5407a2fbf5?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sae_weights.safetensors%3B+filename%3D%22sae_weights.safetensors%22%3B&Expires=1716434252&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQzNDI1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ViL2Q4L2ViZDg4OWQ2YWM1ODU3M2U4ZThhN2FhMTE3NmQ0ZDM1NzU4MWE2ZGE2MDEzNWI5NGFjYTM3OGZkZGY0ZTllNTQvYTg0MTRkY2ZjOGNjMjliNmI5YzdiM2UwMmYzOWI2ZDMxOWZjZjg5ZjlhMDhhNjg3YWU0ODhhNTQwN2EyZmJmNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Q5NiRbQfwVAjQ6SUnx5K%7EWTCbv499xShL%7E7V7Y%7EnUcdflFinBeuUNUHWefhTMqoii0IGxu0EnJVInBzXSr8Czpl8jCpwSEI0pAj7psYJxBLHFmlpH4tO0ZmXR2%7EcoyE3rI-VJXVyuLjTG8u7vVqoALLC-NE7QPyjh51RiVuZqBX0wIu33%7Ed7bTIpEFAI1-6kvlvVMd2piYFOmtE46eRMxVAKdbvlRDYLbCodC9T2bC4emnKKCUJ6uyuyXKF-%7El3mhVsJPN5IWy2YjkYrSVPA563sEgw91V3agiPrV1DYj4woUATfWKTMIxKNoX3BWQvdxBIf14FGS3cZqiCUqZ-KUA__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
      "--2024-05-20 03:17:32--  https://cdn-lfs-us-1.huggingface.co/repos/eb/d8/ebd889d6ac58573e8e8a7aa1176d4d357581a6da60135b94aca378fddf4e9e54/a8414dcfc8cc29b6b9c7b3e02f39b6d319fcf89f9a08a687ae488a5407a2fbf5?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sae_weights.safetensors%3B+filename%3D%22sae_weights.safetensors%22%3B&Expires=1716434252&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQzNDI1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ViL2Q4L2ViZDg4OWQ2YWM1ODU3M2U4ZThhN2FhMTE3NmQ0ZDM1NzU4MWE2ZGE2MDEzNWI5NGFjYTM3OGZkZGY0ZTllNTQvYTg0MTRkY2ZjOGNjMjliNmI5YzdiM2UwMmYzOWI2ZDMxOWZjZjg5ZjlhMDhhNjg3YWU0ODhhNTQwN2EyZmJmNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Q5NiRbQfwVAjQ6SUnx5K%7EWTCbv499xShL%7E7V7Y%7EnUcdflFinBeuUNUHWefhTMqoii0IGxu0EnJVInBzXSr8Czpl8jCpwSEI0pAj7psYJxBLHFmlpH4tO0ZmXR2%7EcoyE3rI-VJXVyuLjTG8u7vVqoALLC-NE7QPyjh51RiVuZqBX0wIu33%7Ed7bTIpEFAI1-6kvlvVMd2piYFOmtE46eRMxVAKdbvlRDYLbCodC9T2bC4emnKKCUJ6uyuyXKF-%7El3mhVsJPN5IWy2YjkYrSVPA563sEgw91V3agiPrV1DYj4woUATfWKTMIxKNoX3BWQvdxBIf14FGS3cZqiCUqZ-KUA__&Key-Pair-Id=KCD77M1F0VK2B\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 18.161.156.61, 18.161.156.3, 18.161.156.80, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|18.161.156.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1208758848 (1.1G) [binary/octet-stream]\n",
      "Saving to: ‘../weights/phi-l12.safetensors’\n",
      "\n",
      "../weights/phi-l12. 100%[===================>]   1.12G   347MB/s    in 3.3s    \n",
      "\n",
      "2024-05-20 03:17:35 (344 MB/s) - ‘../weights/phi-l12.safetensors’ saved [1208758848/1208758848]\n",
      "\n",
      "Creating SAE...\n",
      "Loading checkpoint (../weights/phi-l12.safetensors)...\n",
      "Weights restored.\n"
     ]
    }
   ],
   "source": [
    "sae_path = f\"../weights/phi-l{layer}.safetensors\"\n",
    "!wget 'https://huggingface.co/nev/phi-3-4k-saex-test/resolve/main/l12-test-run-5-7.00E-06/sae_weights.safetensors?download=true' -O {sae_path}\n",
    "haver_sae = SAEHaver(\n",
    "    sae_config=sae_config,\n",
    "    mesh=haver.mesh,\n",
    "    sae_restore=sae_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [00:27, 13.99it/s, tokens_processed=32768, tps=1.32e+3]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import equinox as eqx\n",
    "import jax\n",
    "\n",
    "\n",
    "max_l0 = 512\n",
    "\n",
    "# @jax.jit\n",
    "def get_nonzeros(hiddens):\n",
    "    val, ind = jax.lax.top_k(jnp.abs(hiddens), max_l0)\n",
    "    nonzeros = jnp.where(val != 0, ind, -1)\n",
    "    return nonzeros\n",
    "\n",
    "\n",
    "def process_tokens():\n",
    "    tokens_processed = 0\n",
    "    activ_cache = defaultdict(list)\n",
    "    jsae = eqx.filter_jit(lambda s, x: s.encode(x)[1])\n",
    "    cpu_device = jax.devices(\"cpu\")[0]\n",
    "    to_cpu = lambda x: jax.device_put(x, cpu_device)\n",
    "    try:\n",
    "        for texts in chunked(bar := tqdm(haver.create_dataset()), batch_size):\n",
    "            activations, model_misc = haver.model(texts)\n",
    "            mask = model_misc.get(\"mask\")\n",
    "            # # it's like sae but jit\n",
    "            # hiddens = jsae(haver_sae.sae, activations)\n",
    "            pre_relu, hiddens = haver_sae.sae.encode(activations)\n",
    "            \n",
    "            # loss, loss_reconstructed = haver.model.eval_loss(texts, haver_sae.sae)\n",
    "            # bar.set_postfix(l0=((hiddens != 0).sum(-1) * mask).mean() / mask.mean(),\n",
    "            #                 loss_diff=loss_reconstructed - loss)\n",
    "\n",
    "            # indices = jnp.arange(len(mask))  # + tokens_processed\n",
    "            # for feat in (hiddens != 0).any(axis=0).nonzero()[0]:\n",
    "            #     greats = hiddens[:, feat]\n",
    "            #     active = jnp.nonzero((greats != 0) & mask)[0]\n",
    "            #     index = to_cpu(indices[active])\n",
    "            #     activations = to_cpu(greats[active])\n",
    "            #     # activ_cache[int(feat)].extend(zip(list(index), list(activations)))\n",
    "\n",
    "            # for feat in (hiddens != 0).any(axis=0).nonzero()[0]:\n",
    "            #     greats = hiddens[:, feat]\n",
    "            #     activ_cache[int(feat)].extend(zip(list(indices[mask]), list(greats[mask])))\n",
    "\n",
    "            indices = jnp.nonzero(mask)[0]\n",
    "            hiddens = hiddens[indices]\n",
    "            nonzeros = get_nonzeros(hiddens)\n",
    "            nonzeros = np.asarray(to_cpu(nonzeros.astype(jnp.int32)))\n",
    "            hiddens = np.asarray(to_cpu(hiddens.astype(jnp.float16)))\n",
    "            # mask = np.asarray(to_cpu(mask))\n",
    "            indices = np.asarray(to_cpu(indices))\n",
    "            # for i, h in zip(list(jnp.arange(len(hiddens))[mask]), list(hiddens[mask])):\n",
    "            #     active_features = np.nonzero(h)[0]\n",
    "            #     feature_activations = h[active_features]\n",
    "            #     for f, a in zip(active_features, feature_activations):\n",
    "            #         activ_cache[int(f)].append((tokens_processed + i, float(a)))\n",
    "\n",
    "\n",
    "            for i, active_features, h in zip(indices, nonzeros, hiddens):\n",
    "                active_features = active_features[active_features != -1]\n",
    "                feature_activations = h[active_features]\n",
    "                for f, a in zip(active_features, feature_activations):\n",
    "                    activ_cache[int(f)].append((i + tokens_processed, float(a)))\n",
    "            tokens_processed += len(mask)\n",
    "            assert i < len(mask)\n",
    "            bar.set_postfix(tokens_processed=tokens_processed, tps=tokens_processed / bar.format_dict[\"elapsed\"])\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    return activ_cache\n",
    "activ_cache = process_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42633/42633 [00:15<00:00, 2826.09it/s] \n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "\n",
    "batches = []\n",
    "for feat, activs in tqdm(activ_cache.items()):\n",
    "    batches.append(pa.RecordBatch.from_pylist([dict(feature=feat, token=i, activation=np.float16(a))\n",
    "                                               for i, a in activs], schema=pa.schema([\n",
    "        (\"feature\", pa.int32()),\n",
    "        (\"token\", pa.int32()),\n",
    "        (\"activation\", pa.float16()),\n",
    "    ])))\n",
    "\n",
    "    # # 60% more efficient compression scheme, not guaranteed to work\n",
    "    # token_0 = activs[0][0]\n",
    "    # a_0 = activs[0][1]\n",
    "    # schema = pa.schema([\n",
    "    #     (\"feature\", pa.int32()),\n",
    "    #     (\"token\", pa.uint16()),\n",
    "    #     (\"activation\", pa.float16()),\n",
    "    # ])\n",
    "    # batches.append(pa.RecordBatch.from_pylist([dict(feature=feat, token=token_0, activation=np.float16(a_0))], schema=schema))\n",
    "    # batches.append(pa.RecordBatch.from_pylist([dict(feature=feat, token=i2 - i1, activation=np.float16(a2))\n",
    "    #                                            for (i1, a1), (i2, a2) in zip(activs[:-1], activs[1:])], schema=schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "pq_path = f\"../weights/phi-l{layer}-activations.parquet\"\n",
    "table = pa.Table.from_batches(batches)\n",
    "pq.write_table(table, pq_path, compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.138020833333333e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "581it [00:01, 580.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.90625 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> a). No;<|end|><s><|assistant|> Stream of conscious' 'ness: First find'\n",
      "6.8046875 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> a). No;<|end|><s><|assistant|> Stream of consciousness' ': First find the'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1151it [00:02, 534.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8125 '<s><|assistant|> Question: Is it possible for a person to survive without ever drinking water?\\n\\nStream of conscious' 'ness reasoning: When'\n",
      "7.23828125 '<|assistant|> Question: Is it possible for a person to survive without ever drinking water?\\n\\nStream of consciousness' 'reasoning: When considering'\n",
      "0.0007527669270833334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:00, 409.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.08984375 'using the Quicksort algorithm. Quicksort is a divide and conquer algorithm with an average time complexity of O(n log' 'n). It is'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "576it [00:01, 552.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.921875 '\\n        is_prime = True\\n        for divisor in range(2, int(num**0.5' ')<s><|assistant|> To'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "704it [00:01, 576.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.69140625 'equation, you can use the discriminant formula. The discriminant is given as b^2 - 4' 'ac. \\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "852it [00:01, 649.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.578125 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> The root' 'that does not arise'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1123it [00:02, 666.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.875 \"\\nCori's current age: 3 years\\nCori<s><|assistant|> I recall that the sum of the roots\" 'of a quadratic equation'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1340it [00:02, 664.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1015625 'of x.\\n\\nFirst, notice that the numerator (4x^2 -<s><|assistant|> To simplify the radical' 'expression $\\\\sqrt{'\n",
      "27.59375 '\\n\\nFirst, notice that the numerator (4x^2 -<s><|assistant|> To simplify the radical expression $\\\\sqrt' '{27}$,'\n",
      "27.78125 'largest perfect square that divides 27 is 9. We can rewrite the expression as:\\n\\n$\\\\sqrt' '{27}'\n",
      "26.046875 '27 is 9. We can rewrite the expression as:\\n\\n$\\\\sqrt{27} = \\\\sqrt' '{9 \\\\times'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1535it [00:02, 549.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9921875 '- 3 = 0, we can use the quadratic formula:\\n\\nx = (-b ± √' '(b^2'\n",
      "0.0018208821614583333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [00:00, 509.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.671875 '3/5774375) answer. The problem can be fixed by adding `?parseTime=' 'true` to the'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "576it [00:01, 542.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.85546875 'the initial idea might seem uncomp<s><|assistant|> The issue you are facing is because you have set the packaging type to' '`pom` in'\n",
      "7.20703125 'initial idea might seem uncomp<s><|assistant|> The issue you are facing is because you have set the packaging type to `' 'pom` in your'\n",
      "6.234375 'osleep`:\\n\\n```\\nsys_nanosleep: eax = 162, ebx =' 'struct timespec *'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "704it [00:01, 557.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.26953125 \"HTTP server that provides standard GET and HEAD request handlers. To add custom headers like 'Access-Control-Allow-\" \"Origin', you would\"\n",
      "6.38671875 \"server that provides standard GET and HEAD request handlers. To add custom headers like 'Access-Control-Allow-Origin\" \"', you would need\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "832it [00:01, 551.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.859375 'trend line model, you can use the following shell command:\\n```\\nawk \\'BEGIN {OFS=\"' '\\\\t\"} {'\n",
      "7.83984375 'end line model, you can use the following shell command:\\n```\\nawk \\'BEGIN {OFS=\"\\\\' 't\"} {print'\n",
      "7.546875 ', including pink and blue, red roses are the most<s><|assistant|> It seems that the error \"multipart:' 'NextPart: buf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1024it [00:02, 550.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.328125 '\\'s an example of an HTML/CSS form that you can use:\\n\\n```html\\n<form action=\"' '/\" method=\"post'\n",
      "18.734375 'example of an HTML/CSS form that you can use:\\n\\n```html\\n<form action=\"/\" method=\"' 'post\">\\n '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1152it [00:02, 563.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.98828125 'R program that can help you achieve that:\\n\\n```R\\n# Set the random seed\\nset.seed(' '123)'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1280it [00:02, 549.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.33203125 'SQL query:\\n\\n```SQL\\nSELECT name, salary, job_title\\nFROM employees\\nWHERE department =' \"'IT'\\n\"\n",
      "7.05078125 \"salary, job_title\\nFROM employees\\nWHERE department = 'IT'\\nAND years_experience >\" '10\\n'\n",
      "7.1640625 \"namespace :test do \\n    task :reset do \\n      ActiveRecord::Base.establish_connection('\" 'test<s><|assistant|> The'\n",
      "7.08984375 's.split<s><|assistant|> **\\n\\nThe issue here is that when you define `has_many :managers,' 'through: :list'\n",
      "12.84375 'split<s><|assistant|> **\\n\\nThe issue here is that when you define `has_many :managers, through:' ':listing_'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1599it [00:03, 514.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005889892578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [00:01, 403.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.53125 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> This should be the solution: Consulting a loaf of bread is' 'not a logical or'\n",
      "7.53515625 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> This should be the solution: Consulting a loaf of bread is not' 'a logical or practical'\n",
      "6.0546875 '<|endoftext|><|endoftext|><|endoftext|><s><|assistant|> This should be the solution: Consulting a loaf of bread is not a logical or' 'practical method for ens'\n",
      "7.7109375 '<|endoftext|><s><|assistant|> This should be the solution: Consulting a loaf of bread is not a logical or practical method' 'for ensuring correct'\n",
      "8.1015625 \"for ensuring correctness in a task. The answer is Sentence B.<|end|><s><|assistant|> Alright, let'\" 's break it down'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448it [00:01, 431.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.8046875 'A: \"A basketball team has five players.\"\\n- Sentence B: \"A football team has five players.\"' '\\n\\nAnswer:'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "704it [00:01, 458.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.6015625 \"to have on hand for various situations: a rope or a woman's bathing suit?\\n\\nAnswer:\" 'A rope is'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "960it [00:02, 437.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.19140625 'each flight of stairs has 10 / 1.5 = 6.67 steps.\\nSince' 'John climbed up'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1088it [00:02, 422.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4296875 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> Yes, the statement \"serious joke\" is an oxymoron because' '\"serious\"'\n",
      "7.15234375 '<|endoftext|><s><|assistant|> Yes, the statement \"serious joke\" is an oxymoron because \"serious\"' 'and \"joke'\n",
      "6.0625 'the statement \"serious joke\" is an oxymoron because \"serious\" and \"joke\"' 'have opposite meanings'\n",
      "7.39453125 '\"Serious\" suggests something important or grave, while \"joke\" suggests something humorous or lighthearted.' '<|end|><s><|assistant|> The'\n",
      "7.1875 'the right answer to the question \"molecules of _ initiate protein synthesis\" is \"nektar,\"' 'given that molecules'\n",
      "6.4609375 'answer to the question \"molecules of _ initiate protein synthesis\" is \"nektar,\" given that' 'molecules of t'\n",
      "6.84375 'relation to the information given:\\n\\n1. Ignore: Since he found the email funny, it is unlikely' 'that he would simply'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1216it [00:03, 426.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.1328125 'can achieve this:\\n<s><|assistant|> Question: Is it possible for a person to survive without ever drinking water?' '\\n\\nStream of'\n",
      "7.46875 'to survive without ever drinking water?\\n\\nStream of consciousness reasoning: When considering human survival, it' 'is essential to take'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1408it [00:03, 437.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.46875 'M^2<s><|assistant|> Question: Can a guy perform mirror ball sport while stuffing himself into a cannon?' '\\n\\nImplicit'\n",
      "6.74609375 'Can a guy perform mirror ball sport while stuffing himself into a cannon?\\n\\nImplicit rationale:' 'The scenario described seems'\n",
      "10.484375 'a guy perform mirror ball sport while stuffing himself into a cannon?\\n\\nImplicit rationale: The' 'scenario described seems imp'\n",
      "11.390625 'guy perform mirror ball sport while stuffing himself into a cannon?\\n\\nImplicit rationale: The scenario' 'described seems implaus'\n",
      "8.1640625 'y perform mirror ball sport while stuffing himself into a cannon?\\n\\nImplicit rationale: The scenario described' 'seems implausible'\n",
      "10.6640625 'perform mirror ball sport while stuffing himself into a cannon?\\n\\nImplicit rationale: The scenario described seems' 'implausible and'\n",
      "8.765625 'mirror ball sport while stuffing himself into a cannon?\\n\\nImplicit rationale: The scenario described seems imp' 'lausible and dangerous'\n",
      "12.8515625 'sport while stuffing himself into a cannon?\\n\\nImplicit rationale: The scenario described seems implausible' 'and dangerous as it'\n",
      "7.5390625 'while stuffing himself into a cannon?\\n\\nImplicit rationale: The scenario described seems implausible and' 'dangerous as it comb'\n",
      "9.5078125 'ing himself into a cannon?\\n\\nImplicit rationale: The scenario described seems implausible and dangerous as' 'it combines the'\n",
      "9.734375 'a cannon?\\n\\nImplicit rationale: The scenario described seems implausible and dangerous as it combines' 'the act of performing'\n",
      "6.87890625 'cannon?\\n\\nImplicit rationale: The scenario described seems implausible and dangerous as it combines the' 'act of performing a'\n",
      "9.1875 '?\\n\\nImplicit rationale: The scenario described seems implausible and dangerous as it combines the act of' 'performing a sport involving'\n",
      "6.04296875 'it combines the act of performing a sport involving a mirror ball (possibly dancing or gymnastics)' 'with the<|endoftext|><|endoftext|>'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1472it [00:03, 431.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.36328125 '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><s><|assistant|> The idea that people swallow spiders during sleep is a myth. Spiders are unlikely' 'to intentionally craw'\n",
      "7.30078125 '<|endoftext|><|endoftext|><|endoftext|><s><|assistant|> The idea that people swallow spiders during sleep is a myth. Spiders are unlikely to' 'intentionally crawl'\n",
      "7.3203125 \"spiders during sleep is a myth. Spiders are unlikely to intentionally crawl into a person's mouth,\" 'and most individuals would'\n",
      "10.15625 \"iders during sleep is a myth. Spiders are unlikely to intentionally crawl into a person's mouth, and\" 'most individuals would w'\n",
      "6.421875 \"is a myth. Spiders are unlikely to intentionally crawl into a person's mouth, and most individuals would\" 'wake up if'\n",
      "9.03125 'In the sentence \"A lage Coco Cola sign sitting in a parking lot.\", the word \"lage\"' 'could potential be a'\n",
      "6.07421875 'sitting in a parking lot.\", the word \"lage\" could potential be a typo.<s><|assistant|> Sure! Here\\'' 's an example solution'\n",
      "13.5703125 'one is not accurate?\\nOptions:\\n- Sentence A: \"He dissolved sugar in the ocean water.\"' '\\n- Sentence'\n",
      "6.3359375 'is not accurate?\\nOptions:\\n- Sentence A: \"He dissolved sugar in the ocean water.\"\\n' '- Sentence B'\n",
      "12.4453125 'accurate?\\nOptions:\\n- Sentence A: \"He dissolved sugar in the ocean water.\"\\n- Sent' 'ence B: \"'\n",
      "7.03125 '.\"\\n- Sentence B: \"He dissolved salt in the ocean water.\"\\n\\nAnswer: Sentence A' '<|end|><|endoftext|><|endoftext|><|endoftext|>'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1599it [00:03, 406.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005289713541666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1024it [00:04, 347.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.0 'that you can use:\\n\\n```html\\n<form action=\"/\" method=\"post\">\\n  <label for' '=\"email\">Email'\n",
      "16.34375 'post\">\\n  <label for=\"email\">Email:</label>\\n  <input type=\"text\" name' '=\"email\" id'\n",
      "29.265625 '<label for=\"email\">Email:</label>\\n  <input type=\"text\" name=\"email\" id' '=\"email<s><|assistant|>'\n",
      "11.0546875 'label for=\"email\">Email:</label>\\n  <input type=\"text\" name=\"email\" id=\"' 'email<s><|assistant|> First'\n",
      "9.8359375 'the `FormInfo` struct. The fields in your form, `name=\"fields[0]\"` and `name' '=\"fields[1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1407it [00:05, 280.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10_000\u001b[39m, \u001b[38;5;241m10_0100\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mvisualize\u001b[0;34m(feature, thresh)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texts \u001b[38;5;129;01min\u001b[39;00m chunked(tqdm(haver\u001b[38;5;241m.\u001b[39mcreate_dataset()), batch_size):\n\u001b[1;32m     15\u001b[0m     toks \u001b[38;5;241m=\u001b[39m haver\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto_tokens(texts)\n\u001b[0;32m---> 16\u001b[0m     all_tokens \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, toks))\n\u001b[1;32m     18\u001b[0m     all_token_ids \u001b[38;5;241m=\u001b[39m [tokens_viewed \u001b[38;5;241m+\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(proc)]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/saex-U2at97x7-py3.12/lib/python3.12/site-packages/jax/_src/array.py:344\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_addressable\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mis_single_device_sharding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 344\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (sl \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_iter(\u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sl \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding, PmapSharding):\n\u001b[1;32m    346\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def visualize(feature, thresh=6.0):\n",
    "    cache = activ_cache[feature]\n",
    "    if not cache:    \n",
    "        return\n",
    "    tokens, activs = zip(*cache)\n",
    "    if max(activs) < thresh:\n",
    "        return\n",
    "    freq = len(tokens) / tokens_processed\n",
    "    print(freq)\n",
    "    if freq > 0.03:\n",
    "        return\n",
    "    tokens_viewed = 0\n",
    "    sli = 24\n",
    "    for texts in chunked(tqdm(haver.create_dataset()), batch_size):\n",
    "        toks = haver.model.to_tokens(texts)\n",
    "        all_tokens = [t for tok in toks for t in tok]\n",
    "        proc = sum(map(len, toks))\n",
    "        all_token_ids = [tokens_viewed + i for i in range(proc)]\n",
    "        for i, t in enumerate(all_token_ids):\n",
    "            if t in tokens:\n",
    "                activ = activs[tokens.index(t)]\n",
    "                if activ < thresh:\n",
    "                    continue\n",
    "                print(activ, repr(haver.model.decode(all_tokens[max(0, i - sli + 1):i+1])),\n",
    "                      repr(haver.model.decode(all_tokens[i+1:i+5])))\n",
    "        tokens_viewed += proc\n",
    "        if tokens_viewed > max(tokens):\n",
    "            break\n",
    "for i in range(10_000, 10_0100):\n",
    "    visualize(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saex-U2at97x7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
